{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989e5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('E:\\spark')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ModelSelection').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c878e7",
   "metadata": {},
   "source": [
    "## 3.5 Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cb9ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Severity=2, Wind_Direction='V', Weather_Condition='Clear', Amenity=False, Bump=False, Crossing=False, Give_Way=False, Junction=True, No_Exit=False, Railway=False, Roundabout=False, Station=False, Stop=False, Traffic_Calming=False, Traffic_Signal=False, Turning_Loop=False, Sunrise_Sunset='Day', Civil_Twilight='Day', Nautical_Twilight='Day', Astronomical_Twilight='Day', Distance(mi)=0.0, Temperature(F)=82.9, Wind_Chill(F)=64.92501173068268, Humidity(%)=47.0, Pressure(in)=29.95, Visibility(mi)=10.0, Wind_Speed(mph)=4.6, Precipitation(in)=0.0034345074298293894, Weekday=1, Hour=10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data which has a header. Schema is automatically configured.\n",
    "la_traffic_df = spark.read.csv('LA_Accidents_preprocessed.csv', header=True, inferSchema=True)\n",
    "# Let's see the data. You'll notice nulls.\n",
    "la_traffic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428e2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import LogisticRegression,DecisionTreeClassifier,RandomForestClassifier,NaiveBayes,MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, ChiSqSelector, OneHotEncoder\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import when, log10\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82bad807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "la_traffic_pd = la_traffic_df.toPandas()\n",
    "\n",
    "# feature encoding \n",
    "encoded_df = la_traffic_pd.copy()\n",
    "encoded_df['Severity_encoded'] = encoded_df['Severity'].astype(int)\n",
    "encoded_df\n",
    "encoded_df = encoded_df.drop(\"Severity\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399b4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.get_dummies(encoded_df, columns=[\n",
    "    \"Wind_Direction\", \"Weather_Condition\",\"Sunrise_Sunset\",\n",
    "    \"Civil_Twilight\",\"Nautical_Twilight\",\"Astronomical_Twilight\"])\n",
    "\n",
    "# encoded_df['Distance(mi)'] = encoded_df['Distance(mi)'].apply(\n",
    "#     lambda x: x if x > 0 else 0.003)\n",
    "# encoded_df['log_Distance(mi)'] = np.log10(encoded_df['Distance(mi)'])\n",
    "\n",
    "columns = encoded_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c4a9c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Distance(mi)', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weekday', 'Hour', 'Severity_encoded', 'Wind_Direction_CALM', 'Wind_Direction_E', 'Wind_Direction_ENE', 'Wind_Direction_ESE', 'Wind_Direction_N', 'Wind_Direction_NE', 'Wind_Direction_NNE', 'Wind_Direction_NNW', 'Wind_Direction_NW', 'Wind_Direction_S', 'Wind_Direction_SE', 'Wind_Direction_SSE', 'Wind_Direction_SSW', 'Wind_Direction_SW', 'Wind_Direction_V', 'Wind_Direction_VAR', 'Wind_Direction_W', 'Wind_Direction_WNW', 'Wind_Direction_WSW', 'Weather_Condition_Blowing Dust', 'Weather_Condition_Clear', 'Weather_Condition_Cloudy', 'Weather_Condition_Cloudy / Windy', 'Weather_Condition_Drizzle', 'Weather_Condition_Duststorm', 'Weather_Condition_Fair', 'Weather_Condition_Fair / Windy', 'Weather_Condition_Fog', 'Weather_Condition_Haze', 'Weather_Condition_Haze / Windy', 'Weather_Condition_Heavy Rain', 'Weather_Condition_Heavy T-Storm', 'Weather_Condition_Light Drizzle', 'Weather_Condition_Light Rain', 'Weather_Condition_Light Rain / Windy', 'Weather_Condition_Light Rain with Thunder', 'Weather_Condition_Light Thunderstorms and Rain', 'Weather_Condition_Mist', 'Weather_Condition_Mostly Cloudy', 'Weather_Condition_Mostly Cloudy / Windy', 'Weather_Condition_Overcast', 'Weather_Condition_Partly Cloudy', 'Weather_Condition_Partly Cloudy / Windy', 'Weather_Condition_Patches of Fog', 'Weather_Condition_Rain', 'Weather_Condition_Rain / Windy', 'Weather_Condition_Scattered Clouds', 'Weather_Condition_Shallow Fog', 'Weather_Condition_Smoke', 'Weather_Condition_T-Storm', 'Weather_Condition_Thunder', 'Weather_Condition_Thunderstorm', 'Sunrise_Sunset_Day', 'Sunrise_Sunset_Night', 'Civil_Twilight_Day', 'Civil_Twilight_Night', 'Nautical_Twilight_Day', 'Nautical_Twilight_Night', 'Astronomical_Twilight_Day', 'Astronomical_Twilight_Night']\n"
     ]
    }
   ],
   "source": [
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c29316",
   "metadata": {},
   "source": [
    "## 4 Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de9044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Feature Names: ['Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'Railway', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Distance(mi)', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weekday', 'Hour', 'Wind_Direction_CALM', 'Wind_Direction_E', 'Wind_Direction_ENE', 'Wind_Direction_N', 'Wind_Direction_NE', 'Wind_Direction_NNE', 'Wind_Direction_NW', 'Wind_Direction_S', 'Wind_Direction_SSE', 'Wind_Direction_SSW', 'Wind_Direction_SW', 'Wind_Direction_V', 'Wind_Direction_VAR', 'Wind_Direction_W', 'Wind_Direction_WNW', 'Wind_Direction_WSW', 'Weather_Condition_Clear', 'Weather_Condition_Cloudy', 'Weather_Condition_Fair', 'Weather_Condition_Fair / Windy', 'Weather_Condition_Fog', 'Weather_Condition_Haze', 'Weather_Condition_Heavy Rain', 'Weather_Condition_Light Rain', 'Weather_Condition_Mostly Cloudy', 'Weather_Condition_Overcast', 'Weather_Condition_Partly Cloudy', 'Weather_Condition_Partly Cloudy / Windy', 'Weather_Condition_Patches of Fog', 'Weather_Condition_Rain', 'Weather_Condition_Scattered Clouds', 'Weather_Condition_Smoke', 'Sunrise_Sunset_Day', 'Sunrise_Sunset_Night', 'Civil_Twilight_Day', 'Civil_Twilight_Night', 'Nautical_Twilight_Day', 'Nautical_Twilight_Night', 'Astronomical_Twilight_Day', 'Astronomical_Twilight_Night']\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "import copy\n",
    "\n",
    "la_traffic_df = spark.createDataFrame(encoded_df)\n",
    "# columns.pop(\"Severity_encoded\")\n",
    "selected_columns = copy.deepcopy(columns)\n",
    "selected_columns.remove(\"Severity_encoded\")\n",
    "\n",
    "# Assemble feature vectors\n",
    "assembler = VectorAssembler(inputCols=selected_columns, outputCol=\"features\",handleInvalid=\"keep\")\n",
    "la_traffic_df = assembler.transform(la_traffic_df)\n",
    "\n",
    "# Perform feature selection using ChiSqSelector\n",
    "selector = ChiSqSelector(numTopFeatures=60,featuresCol=\"features\", outputCol=\"selected_features\", labelCol=\"Severity_encoded\")\n",
    "model = selector.fit(la_traffic_df)\n",
    "la_traffic_df = model.transform(la_traffic_df)\n",
    "\n",
    "# show the name of selected features\n",
    "selected_features = model.selectedFeatures\n",
    "selected_feature_names = [selected_columns[i] for i in selected_features]\n",
    "print(\"Selected Feature Names:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238904d5",
   "metadata": {},
   "source": [
    "## 6.1 Conduct exploratory analysis and discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2ae8f",
   "metadata": {},
   "source": [
    "### 6.1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4abf072a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Amenity=False, Bump=False, Crossing=False, Give_Way=False, Junction=True, No_Exit=False, Railway=False, Roundabout=False, Station=False, Stop=False, Traffic_Calming=False, Traffic_Signal=False, Turning_Loop=False, Distance(mi)=0.0, Temperature(F)=82.9, Wind_Chill(F)=64.92501173068268, Humidity(%)=47.0, Pressure(in)=29.95, Visibility(mi)=10.0, Wind_Speed(mph)=4.6, Precipitation(in)=0.0034345074298293894, Weekday=1, Hour=10, Severity_encoded=2, Wind_Direction_CALM=0, Wind_Direction_E=0, Wind_Direction_ENE=0, Wind_Direction_ESE=0, Wind_Direction_N=0, Wind_Direction_NE=0, Wind_Direction_NNE=0, Wind_Direction_NNW=0, Wind_Direction_NW=0, Wind_Direction_S=0, Wind_Direction_SE=0, Wind_Direction_SSE=0, Wind_Direction_SSW=0, Wind_Direction_SW=0, Wind_Direction_V=1, Wind_Direction_VAR=0, Wind_Direction_W=0, Wind_Direction_WNW=0, Wind_Direction_WSW=0, Weather_Condition_Blowing Dust=0, Weather_Condition_Clear=1, Weather_Condition_Cloudy=0, Weather_Condition_Cloudy / Windy=0, Weather_Condition_Drizzle=0, Weather_Condition_Duststorm=0, Weather_Condition_Fair=0, Weather_Condition_Fair / Windy=0, Weather_Condition_Fog=0, Weather_Condition_Haze=0, Weather_Condition_Haze / Windy=0, Weather_Condition_Heavy Rain=0, Weather_Condition_Heavy T-Storm=0, Weather_Condition_Light Drizzle=0, Weather_Condition_Light Rain=0, Weather_Condition_Light Rain / Windy=0, Weather_Condition_Light Rain with Thunder=0, Weather_Condition_Light Thunderstorms and Rain=0, Weather_Condition_Mist=0, Weather_Condition_Mostly Cloudy=0, Weather_Condition_Mostly Cloudy / Windy=0, Weather_Condition_Overcast=0, Weather_Condition_Partly Cloudy=0, Weather_Condition_Partly Cloudy / Windy=0, Weather_Condition_Patches of Fog=0, Weather_Condition_Rain=0, Weather_Condition_Rain / Windy=0, Weather_Condition_Scattered Clouds=0, Weather_Condition_Shallow Fog=0, Weather_Condition_Smoke=0, Weather_Condition_T-Storm=0, Weather_Condition_Thunder=0, Weather_Condition_Thunderstorm=0, Sunrise_Sunset_Day=1, Sunrise_Sunset_Night=0, Civil_Twilight_Day=1, Civil_Twilight_Night=0, Nautical_Twilight_Day=1, Nautical_Twilight_Night=0, Astronomical_Twilight_Day=1, Astronomical_Twilight_Night=0, features=SparseVector(83, {4: 1.0, 14: 82.9, 15: 64.925, 16: 47.0, 17: 29.95, 18: 10.0, 19: 4.6, 20: 0.0034, 21: 1.0, 22: 10.0, 37: 1.0, 43: 1.0, 75: 1.0, 77: 1.0, 79: 1.0, 81: 1.0}), selected_features=SparseVector(60, {4: 1.0, 11: 82.9, 12: 64.925, 13: 47.0, 14: 29.95, 15: 10.0, 16: 4.6, 17: 0.0034, 18: 1.0, 19: 10.0, 31: 1.0, 36: 1.0, 52: 1.0, 54: 1.0, 56: 1.0, 58: 1.0}))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_traffic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744edb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\spark\\python\\lib\\py4j-0.10.9.3-src.zip\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"E:\\spark\\python\\lib\\py4j-0.10.9.3-src.zip\\py4j\\clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"E:\\anaconda\\envs\\python39\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression(featuresCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselected_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeverity_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m, maxIter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the logistic regression model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m lr_model \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainingData\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m lr_model\u001b[38;5;241m.\u001b[39mtransform(testData)\n",
      "File \u001b[1;32mE:\\spark\\python\\pyspark\\ml\\base.py:161\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[1;32mE:\\spark\\python\\pyspark\\ml\\wrapper.py:335\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[1;32m--> 335\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[1;32mE:\\spark\\python\\pyspark\\ml\\wrapper.py:332\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03mFits a Java model to the input dataset.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m    fitted Java model\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\spark\\python\\lib\\py4j-0.10.9.3-src.zip\\py4j\\java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[1;32mE:\\spark\\python\\lib\\py4j-0.10.9.3-src.zip\\py4j\\java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[1;32mE:\\spark\\python\\lib\\py4j-0.10.9.3-src.zip\\py4j\\clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    476\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda\\envs\\python39\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = la_traffic_df.randomSplit([0.9, 0.1])\n",
    "\n",
    "# Create a LogisticRegression classifier\n",
    "lr = LogisticRegression(featuresCol=\"selected_features\", labelCol=\"Severity_encoded\", maxIter=500)\n",
    "\n",
    "# Train the logistic regression model\n",
    "lr_model = lr.fit(trainingData)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = lr_model.transform(testData)\n",
    "train_predictions = lr_model.transform(trainingData)\n",
    "\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "train_evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "train_accuracy = train_evaluator.evaluate(train_predictions)\n",
    "print(f\"Training set accuracy = {train_accuracy}\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "test_accuracy = test_evaluator.evaluate(test_predictions)\n",
    "print(f\"Test set accuracy = {test_accuracy}\")\n",
    "\n",
    "\n",
    "# Print the confusion matrix on training set\n",
    "train_confusion_matrix = train_predictions.crosstab(\"Severity_encoded\", \"prediction\")\n",
    "train_confusion_matrix.show()\n",
    "\n",
    "# Print the confusion matrix on test set\n",
    "test_confusion_matrix = test_predictions.crosstab(\"Severity_encoded\", \"prediction\")\n",
    "test_confusion_matrix.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0247fc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the model coefficients and intercept\n",
    "coefficients = lr_model.coefficientMatrix.toArray()\n",
    "intercept = lr_model.interceptVector \n",
    "print(\"Coefficients: \", coefficients)\n",
    "print(\"Intercept: \", intercept)\n",
    "\n",
    "# Show the model equation\n",
    "feature_columns = selected_feature_names\n",
    "\n",
    "for i,coefficient in enumerate(coefficients):\n",
    "    equation = f\"Logit(P(y={i})) = {intercept}\"\n",
    "    for i, coef in enumerate(coefficient):\n",
    "        equation += f\" + ({coef:.4f} * {feature_columns[i]})\"\n",
    "    print(\"Model Equation: \", equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35fd3eb",
   "metadata": {},
   "source": [
    "### 6.1.2 Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4149248",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and test sets\n",
    "(trainingData, testData) = la_traffic_df.randomSplit([0.9, 0.1])\n",
    "\n",
    "# Create a DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol=\"selected_features\", labelCol=\"Severity_encoded\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[dt])\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt_model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = dt_model.transform(testData)\n",
    "train_predictions = dt_model.transform(trainingData)\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "train_evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "train_accuracy = train_evaluator.evaluate(train_predictions)\n",
    "print(f\"Training set accuracy = {train_accuracy}\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "test_accuracy = test_evaluator.evaluate(test_predictions)\n",
    "print(f\"Test set accuracy = {test_accuracy}\")\n",
    "\n",
    "# Print the confusion matrix on training set\n",
    "train_confusion_matrix = train_predictions.crosstab(\"Severity_encoded\", \"prediction\")\n",
    "train_confusion_matrix.show()\n",
    "\n",
    "# Print the confusion matrix on test set\n",
    "test_confusion_matrix = test_predictions.crosstab(\"Severity_encoded\", \"prediction\")\n",
    "test_confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfdb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(trainingData, testData) = la_traffic_df.randomSplit([0.9, 0.1])\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol=\"selected_features\", labelCol=\"Severity_encoded\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = rf_model.transform(testData)\n",
    "train_predictions = rf_model.transform(trainingData)\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "train_evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "train_accuracy = train_evaluator.evaluate(train_predictions)\n",
    "print(f\"Training set accuracy = {train_accuracy}\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "test_accuracy = test_evaluator.evaluate(test_predictions)\n",
    "print(f\"Test set accuracy = {test_accuracy}\")\n",
    "\n",
    "# Print the confusion matrix on training set\n",
    "train_confusion_matrix = train_predictions.crosstab(\"Severity_encoded\", \"prediction\")\n",
    "train_confusion_matrix.show()\n",
    "\n",
    "# Print the confusion matrix on test set\n",
    "test_confusion_matrix = test_predictions.crosstab(\"Severity_encoded\", \"prediction\")\n",
    "test_confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de137b",
   "metadata": {},
   "source": [
    "### 6.1.4 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(trainingData, testData) = la_traffic_df.randomSplit([0.9, 0.1])\n",
    "\n",
    "# Create a NaiveBayes classifier\n",
    "nb = NaiveBayes(featuresCol=\"selected_features\", labelCol=\"Severity_encoded\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[nb])\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = nb_model.transform(testData)\n",
    "train_predictions = nb_model.transform(trainingData)\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "train_evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "train_accuracy = train_evaluator.evaluate(train_predictions)\n",
    "print(f\"Training set accuracy = {train_accuracy}\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "test_accuracy = test_evaluator.evaluate(test_predictions)\n",
    "print(f\"Test set accuracy = {test_accuracy}\")\n",
    "\n",
    "# Print the confusion matrix on training set\n",
    "train_confusion_matrix = train_predictions.crosstab(\"Severity_encoded\", \"prediction\")\n",
    "train_confusion_matrix.show()\n",
    "\n",
    "# Print the confusion matrix on test set\n",
    "test_confusion_matrix = test_predictions.crosstab(\"Severity_encoded\", \"prediction\")\n",
    "test_confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d13852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
